version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:16-alpine
    container_name: noderr-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: noderr
      POSTGRES_USER: noderr
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-noderr_dev_password}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U noderr"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - noderr-network

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: noderr-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - noderr-network

  # PyTorch ML Service
  ml-service:
    build:
      context: ./ml-service
      dockerfile: Dockerfile
    container_name: noderr-ml-service
    restart: unless-stopped
    environment:
      - GRPC_PORT=50051
      - MODEL_PATH=/app/models
      - LOG_LEVEL=INFO
    volumes:
      - ml_models:/app/models
      - ml_logs:/app/logs
    ports:
      - "50051:50051"
    healthcheck:
      test: ["CMD", "python", "-c", "import grpc; channel = grpc.insecure_channel('localhost:50051'); channel.close()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - noderr-network
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G

  #   # Node Runtime
  node-runtime:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: noderr-node-runtime
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://noderr:${POSTGRES_PASSWORD:-noderr_dev_password}@postgres:5432/noderr
      - REDIS_URL=redis://redis:6379
      - ML_SERVICE_HOST=ml-service
      - ML_SERVICE_PORT=50051
      - STATE_DIR=/app/data/state
    volumes:
      - ./config:/app/config:ro
      - node_logs:/app/logs
      - node_state:/app/data/state:/app/logs
    ports:
      - "8080:8080"
      - "50052:50052"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      ml-service:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "node", "-e", "require('http').get('http://localhost:8080/health', (r) => r.statusCode === 200 ? process.exit(0) : process.exit(1))"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - noderr-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

  # Nginx Load Balancer
  nginx:
    image: nginx:alpine
    container_name: noderr-nginx
    restart: unless-stopped
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - node-runtime
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - noderr-network

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ml_models:
    driver: local
  ml_logs:
    driver: local
  node_data:
    driver: local
   node_logs:
    driver: local
  node_state:
    driver: local
networks:
  noderr-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
